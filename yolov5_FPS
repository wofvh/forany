#!/usr/bin/env python3.6
import rospy
import cv2
import numpy as np
import time
import os

import tensorflow as tf
from PIL import ImageFont, ImageDraw, Image

from datetime import datetime
from sensor_msgs.msg import Image

class yolotflite():
    def __init__(self):
        # model
        self.interpreter = tf.lite.Interpreter(model_path = "/home/nvidia/rb5-media/src/yolo_tflite/scripts/models/yolov4-tiny-256.tflite")
        self.interpreter.allocate_tensors()
        self.input_index = self.interpreter.get_input_details()
        self.output_index = self.interpreter.get_output_details()
        
        # config
        self.height = 480
        self.width = 640
        self.score_th = 0.5
        self.iou_th = 0.5
        self.img_size = 256
        self.input_shape = tf.constant([self.img_size, self.img_size])
        self.input_shape = tf.cast(self.input_shape, dtype=tf.float32)
        self.fontScale = 0.5
        self.show_label = True
        
        # pub, sub
        self.result_pub = rospy.Publisher('/yolotflite/detection_img', Image, queue_size = 1)
        self.subscriber = rospy.Subscriber('/usb_cam/image_raw', Image, self.callback, queue_size = 1)
        
    def callback(self, data):
        t1 = time.time()
        msg = data
        img = np.frombuffer(data.data, dtype=np.uint8).reshape(data.height, data.width, -1)
        img_m = cv2.resize(img, (self.img_size, self.img_size))
        img_m = np.expand_dims(img_m, axis = 0)
        img_m = img_m / 255.
        img_m = np.float32(img_m)
        self.interpreter.set_tensor(self.input_index[0]['index'], img_m)
        self.interpreter.invoke()

        pred = [self.interpreter.get_tensor(self.output_index[i]['index']) for i in range(len(self.output_index))]
        
        # bbox, conf

        scores_max = tf.math.reduce_max(pred[1], axis = -1)
        mask = scores_max >= self.score_th
        class_boxes = tf.boolean_mask(pred[0], mask)
        pred_conf = tf.boolean_mask(pred[1], mask)
        
        class_boxes = tf.reshape(class_boxes, [tf.shape(pred[1])[0], -1, tf.shape(class_boxes)[-1]])
        pred_conf = tf.reshape(pred_conf, [tf.shape(pred[1])[0], -1, tf.shape(pred_conf)[-1]])

        box_xy, box_wh = tf.split(class_boxes, (2, 2), axis=-1)
        
        box_yx = box_xy[..., ::-1]
        box_hw = box_wh[..., ::-1]

        box_mins = (box_yx - (box_hw / 2.)) / self.input_shape
        box_maxes = (box_yx + (box_hw / 2.)) / self.input_shape
        boxes = tf.concat([
            box_mins[..., 0:1],  # y_min
            box_mins[..., 1:2],  # x_min
            box_maxes[..., 0:1],  # y_max
            box_maxes[..., 1:2]  # x_max
        ], axis=-1)

        boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(
                boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),
                scores=tf.reshape(
                    pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),
                max_output_size_per_class=10,
                max_total_size=10,
                iou_threshold=self.iou_th,
                score_threshold=self.score_th
            )
        
        pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]
        out_boxes, out_scores, out_classes, num_boxes = pred_bbox
        # print(pred_bbox)
        if len(num_boxes) > 0:
            for i in range(num_boxes[0]):

                class_ind = int(out_classes[0][i])
                if class_ind != 0:
                    continue
                coor = out_boxes[0][i]
                coor[0] = int(coor[0] * self.height)
                coor[2] = int(coor[2] * self.height)
                coor[1] = int(coor[1] * self.width)
                coor[3] = int(coor[3] * self.width)
                c1, c2 = (int(coor[1]), int(coor[0])), (int(coor[3]), int(coor[2]))
                cv2.rectangle(img, c1, c2, (255,0,0), 2)
                
                if self.show_label:
                    bbox_mess = 'GUEST'
                    t_size = cv2.getTextSize(bbox_mess, 0, self.fontScale, thickness=1)[0]
                    c3 = (c1[0] + t_size[0], c1[1] - t_size[1] - 3)
                    cv2.rectangle(img, c1, (int(np.float32(c3[0])), int(np.float32(c3[1]))), (255,0,0), -1)
                    cv2.putText(img, bbox_mess, (c1[0], int(np.float32(c1[1] - 2))), cv2.FONT_HERSHEY_SIMPLEX,
                                self.fontScale, (255, 255, 255), 1, lineType=cv2.LINE_AA)
        t2 = time.time()
        fps = int(1 / (t2-t1))
        cv2.putText(img, f'FPS: {fps}', (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        msg.data = img.tobytes()
        self.result_pub.publish(msg)
        

def main():
	checker = yolotflite()
	rospy.init_node('yolo_tflite', anonymous=False)
	rospy.spin()
    
        
if __name__ == '__main__':
	main()
